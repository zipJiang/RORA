task:
  type: model-training
  batch_size: 4
  eval_batch_size: 32
  num_epochs: 20
  model:
    type: huggingface-wrapper
    model_handle: t5-base
  trainer:
    warmup_epochs: 1
    type: strategyqa-irm
    optimizer_constructor:
      type: adamw
      learning_rate: 0.0001
    irm_scheduler:
      type: linear-scheduler
      start_val:
        - 0.0
      end_val:
        - ${IRM_COEFFICIENT}
      num_steps: 458
    metrics:
      loss: 
        type: avg-loss
      factual_loss:
        type: stats-extractor
        indexing_path: "environment::factual.loss"
        reduction:
          type: "mean"
      counterfactual_loss:
        type: stats-extractor
        indexing_path: "environment::counterfactual.loss"
        reduction:
          type: "mean"
      factual_grad:
        type: stats-extractor
        indexing_path: "environment::factual.reg"
        reduction:
          type: "mean"
      counterfactual_grad:
        type: stats-extractor
        indexing_path: "environment::counterfactual.reg"
        reduction:
          type: "mean"
      accuracy:
        type: classification-accuracy
    eval_metrics:
      loss: 
        type: avg-loss
      accuracy:
        type: classification-accuracy
    main_metric: loss
    save_dir: ckpt/strategyqa_${REV_MODEL_TYPE}_format=${RATIONALE_FORMAT}_ng=${NUM_NGRAMS}_mf=${MIN_FREQ}_mt=${MAX_TOKENS}_th=${THRESHOLD}_irm=${IRM_COEFFICIENT}
    device: "cuda:0"
  datapath_train: data/strategyqa/rev_format=${RATIONALE_FORMAT}_ng=${NUM_NGRAMS}_mf=${MIN_FREQ}_mt=${MAX_TOKENS}_th=${THRESHOLD}/train
  datapath_eval: data/strategyqa/rev_format=${RATIONALE_FORMAT}_ng=${NUM_NGRAMS}_mf=${MIN_FREQ}_mt=${MAX_TOKENS}_th=${THRESHOLD}/validation