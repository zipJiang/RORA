task:
  type: preprocessing-generation
  data_dir: data/strategyqa/removal_format=${RATIONALE_FORMAT}_ng=${NUM_NGRAMS}_mf=${MIN_FREQ}_mt=${MAX_TOKENS}/
  output_dir: data/strategyqa/generation_format=${RATIONALE_FORMAT}_ng=${NUM_NGRAMS}_mf=${MIN_FREQ}_mt=${MAX_TOKENS}_th=${THRESHOLD}/
  vocab_path: data/strategyqa_vocabs/vocab_format=${RATIONALE_FORMAT}_ng=${NUM_NGRAMS}_mf=${MIN_FREQ}_mt=${MAX_TOKENS}.pt
  model_name: t5-base
  batch_size: 32
  attribution_model:
    type: fasttext-from-best
    path: ckpt/strategyqa_${REMOVAL_MODEL_TYPE}_format=${RATIONALE_FORMAT}_ng=${NUM_NGRAMS}_mf=${MIN_FREQ}_mt=${MAX_TOKENS}
  explainer:
    type: ig-fasttext
    num_steps: 20
    max_input_length: 512
    device: "cuda:0"
  explainer_preprocessor:
    type: strategyqa-global-explanation-preprocessor
    rationale_format: ${RATIONALE_FORMAT}
    batch_size: 32
  generation_collate_fn:
    type: strategyqa-infilling-collate-fn
    rationale_format: ${RATIONALE_FORMAT}
    max_input_length: 256
    max_output_length: 64
    removal_threshold: ${THRESHOLD}
    intervention_on_label: False